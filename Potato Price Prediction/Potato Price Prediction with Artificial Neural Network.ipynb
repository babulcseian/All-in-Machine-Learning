{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a beginner Artificial Neural Network(ANN) project for understanding the Artificial Neural Network(ANN) regression model working principle (potato pricing prediction project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"potato.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important module and library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 16:31:24.617512: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Important module and library  to run the program \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import pandas as np\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>potato_kg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   potato_kg  price\n",
       "0          1     10\n",
       "1          2     20\n",
       "2          3     25\n",
       "3          4     40\n",
       "4          5     55\n",
       "5          6     75\n",
       "6          7     90\n",
       "7          8    100\n",
       "8          9    115\n",
       "9         10    120"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"PotatoPrice.csv\") #df for dataframe,read the data from the csv data file\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "potato_kg    0\n",
       "price        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values=df.isnull().sum()\n",
    "missing_values[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization data in graphical representation(Not necessary, but helps to understand the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc8ef92dd60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For the data visualization \n",
    "%matplotlib inline\n",
    "plt.xlabel('Potato in kilogram(kg)')\n",
    "plt.ylabel('price in Bangladeshi Taka')\n",
    "plt.scatter(df.potato_kg, df.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['potato_kg']] #since x have to be two dimentional or 2D array. So [[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset for Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=10) \n",
    "#if you use \"random_state=10\" then the smaple will be same all the time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>potato_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   potato_kg\n",
       "9         10\n",
       "8          9\n",
       "0          1\n",
       "3          4\n",
       "1          2\n",
       "2          3\n",
       "4          5\n",
       "5          6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>potato_kg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   potato_kg\n",
       "7          8\n",
       "6          7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9    120\n",
       "8    115\n",
       "0     10\n",
       "3     40\n",
       "1     20\n",
       "2     25\n",
       "4     55\n",
       "5     75\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    100\n",
       "6     90\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Model Building "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ANN.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 16:47:06.908409: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#To learn more about Sequential model, go to the link: https://keras.io/getting-started/sequential-model-guide/\n",
    "#to practice more example like this, follow the the link: https://www.youtube.com/watch?v=HCG3hFe1KYY\n",
    "\n",
    "#tensorflow 2 prefer \"tf.keras\" instade of \"keras\".\n",
    "model = tf.keras.Sequential([\n",
    "   tf.keras.layers.Dense(1, input_shape=[1], activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile The ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To learn more about compile follow the link: https://keras.io/models/model/\n",
    "\n",
    "#model.compile(optimizer='sgd',loss='mean_squared_error',metrics=['accuracy'])\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_squared_error',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 3592.5959 - accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 373.1533 - accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 73.0824 - accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 44.9110 - accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 42.0655 - accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 41.5811 - accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 41.3188 - accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 41.0794 - accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 40.8443 - accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 40.6120 - accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 40.3820 - accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 40.1543 - accuracy: 0.0000e+00\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 39.9291 - accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 39.7061 - accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 39.4855 - accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 39.2671 - accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 39.0511 - accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 38.8372 - accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 38.6255 - accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 38.4161 - accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 38.2088 - accuracy: 0.0000e+00\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 38.0036 - accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 37.8006 - accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 37.5997 - accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 37.4008 - accuracy: 0.0000e+00\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 37.2040 - accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 37.0092 - accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 36.8165 - accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 36.6257 - accuracy: 0.0000e+00\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 36.4369 - accuracy: 0.0000e+00\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 36.2501 - accuracy: 0.0000e+00\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 36.0652 - accuracy: 0.0000e+00\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 35.8822 - accuracy: 0.0000e+00\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 35.7011 - accuracy: 0.0000e+00\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 35.5218 - accuracy: 0.0000e+00\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 35.3444 - accuracy: 0.0000e+00\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 35.1689 - accuracy: 0.0000e+00\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 34.9952 - accuracy: 0.0000e+00\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 34.8232 - accuracy: 0.0000e+00\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 34.6530 - accuracy: 0.0000e+00\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 34.4846 - accuracy: 0.0000e+00\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 34.3180 - accuracy: 0.0000e+00\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 34.1530 - accuracy: 0.0000e+00\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 33.9898 - accuracy: 0.0000e+00\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 33.8283 - accuracy: 0.0000e+00\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 33.6684 - accuracy: 0.0000e+00\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 33.5101 - accuracy: 0.0000e+00\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 33.3536 - accuracy: 0.0000e+00\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 33.1986 - accuracy: 0.0000e+00\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 33.0452 - accuracy: 0.0000e+00\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 32.8934 - accuracy: 0.0000e+00\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 32.7432 - accuracy: 0.0000e+00\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 32.5945 - accuracy: 0.0000e+00\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 32.4474 - accuracy: 0.0000e+00\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 32.3018 - accuracy: 0.0000e+00\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 32.1577 - accuracy: 0.0000e+00\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 32.0151 - accuracy: 0.0000e+00\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 31.8739 - accuracy: 0.0000e+00\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 31.7342 - accuracy: 0.0000e+00\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 31.5960 - accuracy: 0.0000e+00\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 31.4592 - accuracy: 0.0000e+00\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 31.3238 - accuracy: 0.0000e+00\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 31.1898 - accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 31.0572 - accuracy: 0.0000e+00\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 30.9260 - accuracy: 0.0000e+00\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 30.7961 - accuracy: 0.0000e+00\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 30.6676 - accuracy: 0.0000e+00\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 30.5403 - accuracy: 0.0000e+00\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 30.4145 - accuracy: 0.0000e+00\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 30.2899 - accuracy: 0.0000e+00\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 30.1665 - accuracy: 0.0000e+00\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 30.0445 - accuracy: 0.0000e+00\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 29.9237 - accuracy: 0.0000e+00\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 29.8042 - accuracy: 0.0000e+00\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 29.6859 - accuracy: 0.0000e+00\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 29.5689 - accuracy: 0.0000e+00\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 29.4530 - accuracy: 0.0000e+00\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 29.3384 - accuracy: 0.0000e+00\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 29.2248 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 29.1126 - accuracy: 0.0000e+00\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 29.0014 - accuracy: 0.0000e+00\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 28.8914 - accuracy: 0.0000e+00\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 28.7826 - accuracy: 0.0000e+00\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 28.6748 - accuracy: 0.0000e+00\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 28.5682 - accuracy: 0.0000e+00\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 28.4627 - accuracy: 0.0000e+00\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 28.3583 - accuracy: 0.0000e+00\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 28.2549 - accuracy: 0.0000e+00\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 28.1527 - accuracy: 0.0000e+00\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 28.0515 - accuracy: 0.0000e+00\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 27.9513 - accuracy: 0.0000e+00\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 27.8522 - accuracy: 0.0000e+00\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 27.7540 - accuracy: 0.0000e+00\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 27.6569 - accuracy: 0.0000e+00\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 27.5608 - accuracy: 0.0000e+00\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 27.4657 - accuracy: 0.0000e+00\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 27.3716 - accuracy: 0.0000e+00\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 27.2785 - accuracy: 0.0000e+00\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 27.1863 - accuracy: 0.0000e+00\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 27.0951 - accuracy: 0.0000e+00\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 27.0048 - accuracy: 0.0000e+00\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 26.9154 - accuracy: 0.0000e+00\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 26.8270 - accuracy: 0.0000e+00\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 26.7395 - accuracy: 0.0000e+00\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 26.6529 - accuracy: 0.0000e+00\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 26.5671 - accuracy: 0.0000e+00\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 26.4823 - accuracy: 0.0000e+00\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 26.3983 - accuracy: 0.0000e+00\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 26.3153 - accuracy: 0.0000e+00\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 26.2330 - accuracy: 0.0000e+00\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 26.1516 - accuracy: 0.0000e+00\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 26.0711 - accuracy: 0.0000e+00\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 25.9914 - accuracy: 0.0000e+00\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 25.9125 - accuracy: 0.0000e+00\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 25.8345 - accuracy: 0.0000e+00\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 25.7572 - accuracy: 0.0000e+00\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 25.6807 - accuracy: 0.0000e+00\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 25.6051 - accuracy: 0.0000e+00\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 25.5302 - accuracy: 0.0000e+00\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 25.4561 - accuracy: 0.0000e+00\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 25.3827 - accuracy: 0.0000e+00\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 25.3101 - accuracy: 0.0000e+00\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 25.2383 - accuracy: 0.0000e+00\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 25.1672 - accuracy: 0.0000e+00\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 25.0968 - accuracy: 0.0000e+00\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 25.0272 - accuracy: 0.0000e+00\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 24.9583 - accuracy: 0.0000e+00\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 24.8901 - accuracy: 0.0000e+00\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 24.8226 - accuracy: 0.0000e+00\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 24.7558 - accuracy: 0.0000e+00\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 24.6897 - accuracy: 0.0000e+00\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 24.6242 - accuracy: 0.0000e+00\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 24.5595 - accuracy: 0.0000e+00\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 24.4954 - accuracy: 0.0000e+00\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 24.4320 - accuracy: 0.0000e+00\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 24.3692 - accuracy: 0.0000e+00\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 24.3071 - accuracy: 0.0000e+00\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 24.2456 - accuracy: 0.0000e+00\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 24.1848 - accuracy: 0.0000e+00\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 24.1246 - accuracy: 0.0000e+00\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 24.0650 - accuracy: 0.0000e+00\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 24.0060 - accuracy: 0.0000e+00\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 23.9477 - accuracy: 0.0000e+00\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 23.8899 - accuracy: 0.0000e+00\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 23.8328 - accuracy: 0.0000e+00\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 23.7762 - accuracy: 0.0000e+00\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 23.7202 - accuracy: 0.0000e+00\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 23.6648 - accuracy: 0.0000e+00\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 23.6099 - accuracy: 0.0000e+00\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 23.5557 - accuracy: 0.0000e+00\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 23.5020 - accuracy: 0.0000e+00\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 23.4488 - accuracy: 0.0000e+00\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 23.3962 - accuracy: 0.0000e+00\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 23.3442 - accuracy: 0.0000e+00\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 23.2926 - accuracy: 0.0000e+00\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 23.2417 - accuracy: 0.0000e+00\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 23.1912 - accuracy: 0.0000e+00\n",
      "Epoch 158/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 23.1413 - accuracy: 0.0000e+00\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 23.0918 - accuracy: 0.0000e+00\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 23.0429 - accuracy: 0.0000e+00\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 22.9945 - accuracy: 0.0000e+00\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 22.9466 - accuracy: 0.0000e+00\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 22.8992 - accuracy: 0.0000e+00\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 22.8523 - accuracy: 0.0000e+00\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 22.8058 - accuracy: 0.0000e+00\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 22.7599 - accuracy: 0.0000e+00\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 22.7144 - accuracy: 0.0000e+00\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 22.6694 - accuracy: 0.0000e+00\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 22.6248 - accuracy: 0.0000e+00\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 22.5807 - accuracy: 0.0000e+00\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 22.5371 - accuracy: 0.0000e+00\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 22.4939 - accuracy: 0.0000e+00\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 22.4512 - accuracy: 0.0000e+00\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 22.4089 - accuracy: 0.0000e+00\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 22.3670 - accuracy: 0.0000e+00\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 22.3256 - accuracy: 0.0000e+00\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 22.2846 - accuracy: 0.0000e+00\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 22.2441 - accuracy: 0.0000e+00\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 22.2039 - accuracy: 0.0000e+00\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 22.1642 - accuracy: 0.0000e+00\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 22.1249 - accuracy: 0.0000e+00\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 22.0859 - accuracy: 0.0000e+00\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 22.0474 - accuracy: 0.0000e+00\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 22.0093 - accuracy: 0.0000e+00\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 21.9716 - accuracy: 0.0000e+00\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 21.9342 - accuracy: 0.0000e+00\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 21.8973 - accuracy: 0.0000e+00\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 21.8608 - accuracy: 0.0000e+00\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 21.8246 - accuracy: 0.0000e+00\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 21.7887 - accuracy: 0.0000e+00\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 21.7533 - accuracy: 0.0000e+00\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 21.7182 - accuracy: 0.0000e+00\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 21.6835 - accuracy: 0.0000e+00\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 21.6491 - accuracy: 0.0000e+00\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 21.6151 - accuracy: 0.0000e+00\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 21.5815 - accuracy: 0.0000e+00\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 21.5482 - accuracy: 0.0000e+00\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 21.5152 - accuracy: 0.0000e+00\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 21.4826 - accuracy: 0.0000e+00\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 21.4503 - accuracy: 0.0000e+00\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 21.4184 - accuracy: 0.0000e+00\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 21.3868 - accuracy: 0.0000e+00\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 21.3555 - accuracy: 0.0000e+00\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 21.3245 - accuracy: 0.0000e+00\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 21.2939 - accuracy: 0.0000e+00\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 21.2635 - accuracy: 0.0000e+00\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 21.2335 - accuracy: 0.0000e+00\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 21.2038 - accuracy: 0.0000e+00\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 21.1744 - accuracy: 0.0000e+00\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 21.1453 - accuracy: 0.0000e+00\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 21.1165 - accuracy: 0.0000e+00\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 21.0880 - accuracy: 0.0000e+00\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 21.0598 - accuracy: 0.0000e+00\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 21.0319 - accuracy: 0.0000e+00\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 21.0043 - accuracy: 0.0000e+00\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 20.9769 - accuracy: 0.0000e+00\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.9499 - accuracy: 0.0000e+00\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 20.9231 - accuracy: 0.0000e+00\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 20.8966 - accuracy: 0.0000e+00\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.8704 - accuracy: 0.0000e+00\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 20.8445 - accuracy: 0.0000e+00\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 20.8188 - accuracy: 0.0000e+00\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.7934 - accuracy: 0.0000e+00\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 20.7682 - accuracy: 0.0000e+00\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.7433 - accuracy: 0.0000e+00\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 20.7187 - accuracy: 0.0000e+00\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 20.6943 - accuracy: 0.0000e+00\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 20.6701 - accuracy: 0.0000e+00\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 20.6462 - accuracy: 0.0000e+00\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 20.6226 - accuracy: 0.0000e+00\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 20.5992 - accuracy: 0.0000e+00\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.5761 - accuracy: 0.0000e+00\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.5532 - accuracy: 0.0000e+00\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 20.5305 - accuracy: 0.0000e+00\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.5080 - accuracy: 0.0000e+00\n",
      "Epoch 236/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 20.4858 - accuracy: 0.0000e+00\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 20.4639 - accuracy: 0.0000e+00\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.4421 - accuracy: 0.0000e+00\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 20.4206 - accuracy: 0.0000e+00\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.3993 - accuracy: 0.0000e+00\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.3782 - accuracy: 0.0000e+00\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 20.3573 - accuracy: 0.0000e+00\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.3367 - accuracy: 0.0000e+00\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.3162 - accuracy: 0.0000e+00\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.2960 - accuracy: 0.0000e+00\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 20.2760 - accuracy: 0.0000e+00\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 20.2562 - accuracy: 0.0000e+00\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.2366 - accuracy: 0.0000e+00\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 20.2172 - accuracy: 0.0000e+00\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 20.1980 - accuracy: 0.0000e+00\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 20.1790 - accuracy: 0.0000e+00\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 20.1602 - accuracy: 0.0000e+00\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.1416 - accuracy: 0.0000e+00\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 20.1231 - accuracy: 0.0000e+00\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 20.1049 - accuracy: 0.0000e+00\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.0869 - accuracy: 0.0000e+00\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 20.0690 - accuracy: 0.0000e+00\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 20.0513 - accuracy: 0.0000e+00\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 20.0339 - accuracy: 0.0000e+00\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 20.0166 - accuracy: 0.0000e+00\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.9994 - accuracy: 0.0000e+00\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.9825 - accuracy: 0.0000e+00\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.9657 - accuracy: 0.0000e+00\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.9491 - accuracy: 0.0000e+00\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.9327 - accuracy: 0.0000e+00\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.9164 - accuracy: 0.0000e+00\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.9003 - accuracy: 0.0000e+00\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8844 - accuracy: 0.0000e+00\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8686 - accuracy: 0.0000e+00\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.8530 - accuracy: 0.0000e+00\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8376 - accuracy: 0.0000e+00\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 19.8223 - accuracy: 0.0000e+00\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 19.8072 - accuracy: 0.0000e+00\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.7922 - accuracy: 0.0000e+00\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7774 - accuracy: 0.0000e+00\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.7628 - accuracy: 0.0000e+00\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7483 - accuracy: 0.0000e+00\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7339 - accuracy: 0.0000e+00\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.7197 - accuracy: 0.0000e+00\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.7056 - accuracy: 0.0000e+00\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.6917 - accuracy: 0.0000e+00\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.6780 - accuracy: 0.0000e+00\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.6643 - accuracy: 0.0000e+00\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 19.6508 - accuracy: 0.0000e+00\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.6375 - accuracy: 0.0000e+00\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.6243 - accuracy: 0.0000e+00\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.6112 - accuracy: 0.0000e+00\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.5983 - accuracy: 0.0000e+00\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.5855 - accuracy: 0.0000e+00\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 19.5728 - accuracy: 0.0000e+00\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 19.5602 - accuracy: 0.0000e+00\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.5478 - accuracy: 0.0000e+00\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 19.5355 - accuracy: 0.0000e+00\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.5234 - accuracy: 0.0000e+00\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.5114 - accuracy: 0.0000e+00\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 19.4995 - accuracy: 0.0000e+00\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.4877 - accuracy: 0.0000e+00\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.4760 - accuracy: 0.0000e+00\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.4645 - accuracy: 0.0000e+00\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.4530 - accuracy: 0.0000e+00\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.4418 - accuracy: 0.0000e+00\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.4306 - accuracy: 0.0000e+00\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 19.4195 - accuracy: 0.0000e+00\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.4085 - accuracy: 0.0000e+00\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.3977 - accuracy: 0.0000e+00\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.3869 - accuracy: 0.0000e+00\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.3763 - accuracy: 0.0000e+00\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 19.3658 - accuracy: 0.0000e+00\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.3554 - accuracy: 0.0000e+00\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.3451 - accuracy: 0.0000e+00\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.3349 - accuracy: 0.0000e+00\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.3249 - accuracy: 0.0000e+00\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 19.3149 - accuracy: 0.0000e+00\n",
      "Epoch 314/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 7ms/step - loss: 19.3050 - accuracy: 0.0000e+00\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.2952 - accuracy: 0.0000e+00\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.2856 - accuracy: 0.0000e+00\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.2760 - accuracy: 0.0000e+00\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.2665 - accuracy: 0.0000e+00\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.2571 - accuracy: 0.0000e+00\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.2479 - accuracy: 0.0000e+00\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 363ms/step - loss: 19.2387 - accuracy: 0.0000e+00\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.2296 - accuracy: 0.0000e+00\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 19.2206 - accuracy: 0.0000e+00\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.2117 - accuracy: 0.0000e+00\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.2029 - accuracy: 0.0000e+00\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.1942 - accuracy: 0.0000e+00\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.1855 - accuracy: 0.0000e+00\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.1770 - accuracy: 0.0000e+00\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.1686 - accuracy: 0.0000e+00\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 19.1602 - accuracy: 0.0000e+00\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.1519 - accuracy: 0.0000e+00\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.1437 - accuracy: 0.0000e+00\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.1356 - accuracy: 0.0000e+00\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.1276 - accuracy: 0.0000e+00\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.1196 - accuracy: 0.0000e+00\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.1118 - accuracy: 0.0000e+00\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.1040 - accuracy: 0.0000e+00\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.0963 - accuracy: 0.0000e+00\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.0887 - accuracy: 0.0000e+00\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.0812 - accuracy: 0.0000e+00\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.0737 - accuracy: 0.0000e+00\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.0663 - accuracy: 0.0000e+00\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.0590 - accuracy: 0.0000e+00\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.0518 - accuracy: 0.0000e+00\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.0446 - accuracy: 0.0000e+00\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.0375 - accuracy: 0.0000e+00\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 19.0305 - accuracy: 0.0000e+00\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.0236 - accuracy: 0.0000e+00\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 19.0167 - accuracy: 0.0000e+00\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 19.0099 - accuracy: 0.0000e+00\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 19.0032 - accuracy: 0.0000e+00\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.9966 - accuracy: 0.0000e+00\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.9900 - accuracy: 0.0000e+00\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.9835 - accuracy: 0.0000e+00\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.9770 - accuracy: 0.0000e+00\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.9706 - accuracy: 0.0000e+00\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.9643 - accuracy: 0.0000e+00\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.9581 - accuracy: 0.0000e+00\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.9519 - accuracy: 0.0000e+00\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.9457 - accuracy: 0.0000e+00\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.9397 - accuracy: 0.0000e+00\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.9337 - accuracy: 0.0000e+00\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.9277 - accuracy: 0.0000e+00\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.9219 - accuracy: 0.0000e+00\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.9161 - accuracy: 0.0000e+00\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.9103 - accuracy: 0.0000e+00\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.9046 - accuracy: 0.0000e+00\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.8990 - accuracy: 0.0000e+00\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.8934 - accuracy: 0.0000e+00\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.8879 - accuracy: 0.0000e+00\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.8824 - accuracy: 0.0000e+00\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.8770 - accuracy: 0.0000e+00\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.8717 - accuracy: 0.0000e+00\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.8664 - accuracy: 0.0000e+00\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.8611 - accuracy: 0.0000e+00\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.8559 - accuracy: 0.0000e+00\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.8508 - accuracy: 0.0000e+00\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.8457 - accuracy: 0.0000e+00\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.8407 - accuracy: 0.0000e+00\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.8357 - accuracy: 0.0000e+00\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.8308 - accuracy: 0.0000e+00\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.8259 - accuracy: 0.0000e+00\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.8211 - accuracy: 0.0000e+00\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.8163 - accuracy: 0.0000e+00\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.8116 - accuracy: 0.0000e+00\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.8069 - accuracy: 0.0000e+00\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.8023 - accuracy: 0.0000e+00\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.7977 - accuracy: 0.0000e+00\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.7932 - accuracy: 0.0000e+00\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.7887 - accuracy: 0.0000e+00\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.7843 - accuracy: 0.0000e+00\n",
      "Epoch 392/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 18.7799 - accuracy: 0.0000e+00\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.7755 - accuracy: 0.0000e+00\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.7712 - accuracy: 0.0000e+00\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.7670 - accuracy: 0.0000e+00\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.7628 - accuracy: 0.0000e+00\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.7586 - accuracy: 0.0000e+00\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 18.7545 - accuracy: 0.0000e+00\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 18.7504 - accuracy: 0.0000e+00\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.7463 - accuracy: 0.0000e+00\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.7423 - accuracy: 0.0000e+00\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.7384 - accuracy: 0.0000e+00\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.7345 - accuracy: 0.0000e+00\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.7306 - accuracy: 0.0000e+00\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.7268 - accuracy: 0.0000e+00\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.7230 - accuracy: 0.0000e+00\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.7192 - accuracy: 0.0000e+00\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.7155 - accuracy: 0.0000e+00\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.7118 - accuracy: 0.0000e+00\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.7082 - accuracy: 0.0000e+00\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.7046 - accuracy: 0.0000e+00\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.7010 - accuracy: 0.0000e+00\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.6975 - accuracy: 0.0000e+00\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.6940 - accuracy: 0.0000e+00\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.6905 - accuracy: 0.0000e+00\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.6871 - accuracy: 0.0000e+00\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.6837 - accuracy: 0.0000e+00\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.6803 - accuracy: 0.0000e+00\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.6770 - accuracy: 0.0000e+00\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.6737 - accuracy: 0.0000e+00\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.6705 - accuracy: 0.0000e+00\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 18.6673 - accuracy: 0.0000e+00\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 18.6641 - accuracy: 0.0000e+00\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.6609 - accuracy: 0.0000e+00\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.6578 - accuracy: 0.0000e+00\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.6548 - accuracy: 0.0000e+00\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.6517 - accuracy: 0.0000e+00\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.6487 - accuracy: 0.0000e+00\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.6457 - accuracy: 0.0000e+00\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.6427 - accuracy: 0.0000e+00\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.6398 - accuracy: 0.0000e+00\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.6369 - accuracy: 0.0000e+00\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.6340 - accuracy: 0.0000e+00\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.6312 - accuracy: 0.0000e+00\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.6284 - accuracy: 0.0000e+00\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.6256 - accuracy: 0.0000e+00\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 18.6229 - accuracy: 0.0000e+00\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.6201 - accuracy: 0.0000e+00\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.6174 - accuracy: 0.0000e+00\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.6148 - accuracy: 0.0000e+00\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.6121 - accuracy: 0.0000e+00\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.6095 - accuracy: 0.0000e+00\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.6069 - accuracy: 0.0000e+00\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.6044 - accuracy: 0.0000e+00\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.6018 - accuracy: 0.0000e+00\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5993 - accuracy: 0.0000e+00\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5969 - accuracy: 0.0000e+00\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5944 - accuracy: 0.0000e+00\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.5920 - accuracy: 0.0000e+00\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.5895 - accuracy: 0.0000e+00\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5872 - accuracy: 0.0000e+00\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.5848 - accuracy: 0.0000e+00\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.5825 - accuracy: 0.0000e+00\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5802 - accuracy: 0.0000e+00\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5779 - accuracy: 0.0000e+00\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.5756 - accuracy: 0.0000e+00\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.5734 - accuracy: 0.0000e+00\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5712 - accuracy: 0.0000e+00\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5690 - accuracy: 0.0000e+00\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5668 - accuracy: 0.0000e+00\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.5647 - accuracy: 0.0000e+00\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.5626 - accuracy: 0.0000e+00\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5605 - accuracy: 0.0000e+00\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 18.5584 - accuracy: 0.0000e+00\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5564 - accuracy: 0.0000e+00\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5543 - accuracy: 0.0000e+00\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.5523 - accuracy: 0.0000e+00\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.5503 - accuracy: 0.0000e+00\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5483 - accuracy: 0.0000e+00\n",
      "Epoch 470/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 18.5464 - accuracy: 0.0000e+00\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.5444 - accuracy: 0.0000e+00\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.5425 - accuracy: 0.0000e+00\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5406 - accuracy: 0.0000e+00\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.5388 - accuracy: 0.0000e+00\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5369 - accuracy: 0.0000e+00\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.5351 - accuracy: 0.0000e+00\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5333 - accuracy: 0.0000e+00\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.5315 - accuracy: 0.0000e+00\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.5297 - accuracy: 0.0000e+00\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5279 - accuracy: 0.0000e+00\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5262 - accuracy: 0.0000e+00\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.5245 - accuracy: 0.0000e+00\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.5228 - accuracy: 0.0000e+00\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.5211 - accuracy: 0.0000e+00\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5194 - accuracy: 0.0000e+00\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 18.5177 - accuracy: 0.0000e+00\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.5161 - accuracy: 0.0000e+00\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5145 - accuracy: 0.0000e+00\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.5129 - accuracy: 0.0000e+00\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.5113 - accuracy: 0.0000e+00\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.5097 - accuracy: 0.0000e+00\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.5082 - accuracy: 0.0000e+00\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5066 - accuracy: 0.0000e+00\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.5051 - accuracy: 0.0000e+00\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.5036 - accuracy: 0.0000e+00\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.5021 - accuracy: 0.0000e+00\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.5006 - accuracy: 0.0000e+00\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 18.4992 - accuracy: 0.0000e+00\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 18.4977 - accuracy: 0.0000e+00\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 18.4963 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc8d0f5efd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[96.74229 ],\n",
       "       [83.723305]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    100\n",
       "6     90\n",
       "Name: price, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate The Model Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 25.0048 - accuracy: 0.0000e+00 - 117ms/epoch - 117ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here you can clearly see the accuricy is bad, loss is  high comparatively. So, if you are doing any project where you have few data it is better to use machin learning rather artificial neural network.Here the our test data is so small that it cann't even calculate for accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict The Output Manually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential/dense/MatMul' defined at (most recent call last):\n    File \"/opt/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/anaconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/anaconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/anaconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/opt/anaconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/opt/anaconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/0x/88y563mn28n7lfvhpln11vqw0000gn/T/ipykernel_42022/3424049626.py\", line 3, in <module>\n      print(model.predict([1000]))\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2350, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2137, in predict_function\n      return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2123, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2111, in run_step\n      outputs = model.predict_step(data)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2079, in predict_step\n      return self(x, training=False)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/layers/core/dense.py\", line 241, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'sequential/dense/MatMul'\nIn[0] and In[1] has different ndims: [1] vs. [1,1]\n\t [[{{node sequential/dense/MatMul}}]] [Op:__inference_predict_function_8772]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0x/88y563mn28n7lfvhpln11vqw0000gn/T/ipykernel_42022/3424049626.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Give any unknown potato kilogram value,to know the price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#(N.B: the potato kilogram value have to be any value upto 1,for the decent prediction. Since our fitted data potato_kg range is 1 to 7)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/dense/MatMul' defined at (most recent call last):\n    File \"/opt/anaconda3/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/anaconda3/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/anaconda3/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/opt/anaconda3/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/anaconda3/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/opt/anaconda3/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/opt/anaconda3/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 390, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n      result = self._run_cell(\n    File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n      return runner(coro)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/0x/88y563mn28n7lfvhpln11vqw0000gn/T/ipykernel_42022/3424049626.py\", line 3, in <module>\n      print(model.predict([1000]))\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2350, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2137, in predict_function\n      return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2123, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2111, in run_step\n      outputs = model.predict_step(data)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 2079, in predict_step\n      return self(x, training=False)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/sequential.py\", line 413, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/anaconda3/lib/python3.9/site-packages/keras/layers/core/dense.py\", line 241, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'sequential/dense/MatMul'\nIn[0] and In[1] has different ndims: [1] vs. [1,1]\n\t [[{{node sequential/dense/MatMul}}]] [Op:__inference_predict_function_8772]"
     ]
    }
   ],
   "source": [
    "# Give any unknown potato kilogram value,to know the price\n",
    "#(N.B: the potato kilogram value have to be any value upto 1,for the decent prediction. Since our fitted data potato_kg range is 1 to 7)\n",
    "print(model.predict([1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take User Input To Know The Potato Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To know the potato price,Enter the potato killogram upto 1 : 400\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "So 400.0  killogram potato price is = 5200.18310546875  Taka\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0x/88y563mn28n7lfvhpln11vqw0000gn/T/ipykernel_42022/1050504409.py:9: DeprecationWarning: np.asscalar(a) is deprecated since NumPy v1.16, use a.item() instead\n",
      "  price=np.asscalar(np.array(my_prediction)) #convert vector into scalar using this one line only\n"
     ]
    }
   ],
   "source": [
    "x=float(input('To know the potato price,Enter the potato killogram upto 1 : '))\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "my_prediction=model.predict([[x]])\n",
    "#print(my_prediction)\n",
    "\n",
    "price=np.asscalar(np.array(my_prediction)) #convert vector into scalar using this one line only\n",
    "\n",
    "#convert vector into scalar using below two lines\n",
    "#price=np.array(my_prediction) \n",
    "#price=price.item()\n",
    "\n",
    "print('So',x,' killogram potato price is =',price ,' Taka')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###to find your tensorflow running version run\n",
    "#tf.VERSION\n",
    "###or\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
